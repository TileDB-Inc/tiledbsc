---
title: "Converting HDF5 files from 10x Genomics"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Converting HDF5 files from 10x Genomics}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
params:
  cleanup: TRUE
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Setup

```{r setup}
library(tiledb)
library(Seurat)
library(tiledbsc)

h5_url <- "https://cf.10xgenomics.com/samples/cell-exp/6.1.0/500_PBMC_3p_LT_Chromium_X/500_PBMC_3p_LT_Chromium_X_filtered_feature_bc_matrix.h5"
h5_file <- basename(h5_url)
```

In this vignette we'll work with a small example dataset provided by 10x Genomics containing ~500 Human peripheral blood mononuclear cells (PBMCs). More information about this data is available [here](https://www.10xgenomics.com/resources/datasets/500-human-pbm-cs-3-lt-v-3-1-chromium-x-3-1-low-6-1-0).

Let's download a local of the HDF5 file.

```{r eval=!file.exists(h5_file)}
download.file(h5_url, dest = h5_file)
```

## Conversion

Use `tiledbsc`'s conversion function to create a TileDB array containing the same data.

```{r}
tdb_10x_uri <- H510xToTiledb(source = h5_file, overwrite = TRUE, tile_order = "COL_MAJOR")
tdb_10x_uri
```

This created a new directory in your current working directory named `r tdb_10x_uri`, which contains the TileDB array.

```{r}
dir(tdb_10x_uri)
```

## Querying

We can use the tiledb package to slice the array without loading the entire dataset into memory.

Open the array:

```{r}
tdb_array <- tiledb_array(tdb_10x_uri, return_as = "tibble")
```

Use standard R indexing to slice by feature

```{r}
tdb_array["B2M", ]
```

or barcode:

```{r}
tdb_array[, "AATCACGGTCTTCATT-1"]
```

You can also retrieve counts for multiple genes across all barcodes:

```{r}
# specify genes of interest
genes <- c("B2M", "EEF1A1", "IGKC", "MALAT1", "MT-ATP6", "MT-CO1")
selected_ranges(tdb_array) <- list(feature = cbind(genes, genes))

# run the query
tbl_counts <- tdb_array[]

boxplot(data ~ feature, data = tbl_counts, col = "skyblue", pch = 16)
```

## Analyzing with Seurat

In order to use *Seurat* to analyze 10x count data stored with TileDB you'll first need to read it into into memory.

```{r}
count_mat <- Read10x_tiledb(tdb_10x_uri, verbose = TRUE)
head(count_mat)
```

Similar to `Seurat::Read10X_h5()` this returns a `dgCMatrix`, which can then be converted to a `Seurat` object.

```{r}
pbmc3p <- Seurat::CreateSeuratObject(counts = count_mat, project = "pbmc3p")
```

We can then treat this just as you would any `Seurat` object and apply any of Seurat's methods that each update the object with a new set of results/annotations.

### Normalize

```{r}
pbmc3p <- NormalizeData(pbmc3p, normalization.method = "LogNormalize", scale.factor = 10000)
```

### Feature Selection

```{r}
pbmc3p <- FindVariableFeatures(pbmc3p, selection.method = "vst", nfeatures = 2000)
```

### PCA

```{r}
pbmc3p <- ScaleData(pbmc3p)
pbmc3p <- RunPCA(pbmc3p, features = VariableFeatures(object = pbmc3p))
```


### Cluster

```{r}
pbmc3p <- FindNeighbors(pbmc3p, dims = 1:10)
pbmc3p <- FindClusters(pbmc3p, resolution = 0.5)
```

## Write to disk

Our `Seurat` object has been updated to include the outputs and results from each of the steps above in our example pipeline. We can then save this object as a group of TileDB arrays, with one array per slot.

```{r}
tdb_seurat_uri <- "pbmc3p-array"
writeTiledbSeurat(pbmc3p, base_uri = tdb_seurat_uri)
```

## Session

```{r}
sessionInfo()
```

```{r cleanup, include=FALSE, eval=params$cleanup}
unlink(tdb_10x_uri, recursive = TRUE)
unlink(tdb_seurat_uri, recursive = TRUE)
unlink(h5_file)
```



